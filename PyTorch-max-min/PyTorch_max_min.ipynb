{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最大値、最小値を取得するtorch.max、torch.min\n",
    "https://take-tech-engineer.com/pytorch-max-min/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iHyYqFdjBRNF"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9hXX9StIBVRf",
    "outputId": "e5c03afd-d53e-428d-e0f3-738e2c4ac80e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n",
      "torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12],])\n",
    "print(a)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MDPTTKyKBq0N",
    "outputId": "e8e1c74d-4102-4415-c575-674045c2bf11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12)\n"
     ]
    }
   ],
   "source": [
    "print(torch.max(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NTIM4ZWLBvg2",
    "outputId": "b139d067-d1f4-45c5-b701-d227a2da6383"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([ 9, 10, 11, 12]),\n",
      "indices=tensor([2, 2, 2, 2]))\n",
      "tensor([ 9, 10, 11, 12])\n",
      "torch.return_types.max(\n",
      "values=tensor([ 4,  8, 12]),\n",
      "indices=tensor([3, 3, 3]))\n",
      "tensor([ 4,  8, 12])\n"
     ]
    }
   ],
   "source": [
    "print(torch.max(a,dim=0))\n",
    "\n",
    "print(torch.max(a,dim=0).values)\n",
    "\n",
    "print(torch.max(a,dim=1))\n",
    "\n",
    "print(torch.max(a,dim=1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G36XJcZYDSKD",
    "outputId": "3e4cc194-1447-4bbd-f6b1-6c3fe6ab2d34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "print(torch.min(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XqJCWx6cIWuu",
    "outputId": "d74e6e53-63ea-42bc-b691-e7aa44433167"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.min(\n",
      "values=tensor([1, 2, 3, 4]),\n",
      "indices=tensor([0, 0, 0, 0]))\n",
      "tensor([1, 2, 3, 4])\n",
      "torch.return_types.min(\n",
      "values=tensor([1, 5, 9]),\n",
      "indices=tensor([0, 0, 0]))\n",
      "tensor([1, 5, 9])\n"
     ]
    }
   ],
   "source": [
    "print(torch.min(a,dim=0))\n",
    "\n",
    "print(torch.min(a,dim=0).values)\n",
    "\n",
    "print(torch.min(a,dim=1))\n",
    "\n",
    "print(torch.min(a,dim=1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Raa9IezIleW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PyTorch-max-min.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
